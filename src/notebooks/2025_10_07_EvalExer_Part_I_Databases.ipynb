{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "st4fJtML5xID"
      },
      "source": [
        "# Evaluated Exercise - Part 1: Databases\n",
        "\n",
        "Please upload an html-version of your final version into the drop-zone in Moodle. If you have any issues with it, send the final version to guido.moeser@gmail.com.   \n",
        "Release Date: 2025-10-07\n",
        "\n",
        "## Final Submission Instructions\n",
        "\n",
        "1. Complete all sections in the notebook.\n",
        "2. Add explanations of all parts. **Explanations are the most important part for the grading.**\n",
        "3. Comment on which configuration you found best and why. **Comments are the second most important part for the grading.**\n",
        "4. Export your Jupyter Notebook to HTML and send the HTML-version.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxVuHeJB6QAy"
      },
      "source": [
        "# Topic: Building a simple Retrieval-Augmented Retrieval System with SQLite (in-memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvruTfg86TVg"
      },
      "source": [
        "## 1 – Import the required packages\n",
        "\n",
        "**Required packages etc:**\n",
        "- sqlite3\n",
        "- pandas\n",
        "- numpy\n",
        "- from sklearn.metrics.pairwise we need cosine_similarity\n",
        "- from the SentenceTransformer package we need the SentenceTransformer class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "J3Ad435O5wcY"
      },
      "outputs": [],
      "source": [
        "# Load the minimal set of packages we will need\n",
        "\n",
        "'''\n",
        "In order to manage dependencies. in this project it will be used pixi since it is the most versatile tool.\n",
        "https://pixi.sh/dev/\n",
        "'''\n",
        "# Uncomment below lines to installthe libraries required in this project IF using pixi package manager\n",
        "# %pixi add pandas numpy sentence-transformers scikit-learn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoFe4yVt6WND"
      },
      "source": [
        "**Explanation:**\n",
        "- We will only use the core Python SQLite library and three data-science packages: pandas, numpy, and sentence-transformers.\n",
        "- No extra dependencies are needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcmAqaRK6bPm"
      },
      "source": [
        "## 2 – Provide your own texts\n",
        "\n",
        "Please insert 10 texts of length > 200 words (news articles, wikipedia article (parts of it), product descriptions, product reviews etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "A9-Bn4CN6Vhz"
      },
      "outputs": [],
      "source": [
        "# Each of these text samples are samples of length ~250 and are about Harry Potter's critics.\n",
        "texts = [\n",
        "    \"The Harry Potter series is one of the most influential works of modern literature, and its impact extends far beyond fantasy fiction. J.K. Rowling’s ability to construct a detailed magical world that coexists with our own is nothing short of remarkable. From the moment readers board the Hogwarts Express, they are drawn into a setting filled with mystery, friendship, and wonder. The series’ appeal lies in its balance between escapism and emotional realism. Beneath the spells and potions, Rowling crafts a story about belonging, courage, and moral choices. Harry’s journey from an unwanted orphan to a hero who chooses compassion over revenge resonates deeply with readers of all ages. The books also celebrate education and curiosity — Hogwarts becomes a symbol of learning and self-discovery. However, what truly cements Harry Potter’s place in literary history is how it rekindled a love for reading among young audiences in a digital age. Millions of children who once disliked books found themselves captivated by this magical universe. For many, it was their first major reading adventure. While some critics question its literary sophistication, its cultural and emotional influence is undeniable. Harry Potter reminds us that imagination is a form of power — one capable of inspiring hope, unity, and resilience in a world that often feels divided.\",\n",
        "    \"At its core, Harry Potter is not merely a fantasy series; it’s a profound coming-of-age narrative. The magic, creatures, and enchanted castles are captivating, but the emotional depth behind them is what makes the series timeless. Readers grow alongside Harry — from a lonely, mistreated child living in a cupboard to a young adult facing moral dilemmas and loss. Rowling’s genius lies in her ability to mirror the process of growing up through magic: each spell learned, each friendship tested, and each battle fought symbolizes lessons about identity and courage. The early books are playful, full of wonder and innocence, but as the series progresses, the tone darkens — reflecting both the maturation of the characters and the readers themselves. The deaths of beloved figures like Sirius and Dumbledore are not just plot points; they teach the painful but essential truth that growing up often means facing grief and uncertainty. The beauty of the story lies in its emotional honesty — magic doesn’t erase pain, but it gives people strength to face it. The final book, The Deathly Hallows, brings everything full circle, showing that real heroism comes from love, sacrifice, and self-understanding. For anyone who grew up with these books, Harry Potter is not just fiction; it’s a mirror of adolescence, courage, and transformation.\",\n",
        "    \"The Harry Potter franchise is a cultural milestone unlike any other in recent literary history. When The Philosopher’s Stone was released in 1997, few could have predicted that it would spark a global phenomenon spanning books, films, theme parks, and countless fan communities. The series not only redefined the fantasy genre but also reshaped publishing, proving that children’s literature could captivate readers of all ages. Midnight book releases became global events; fans dressed in robes and waved wands, demonstrating the unparalleled reach of Rowling’s world-building. The story’s universal themes — love, friendship, identity, and resistance against tyranny — make it relatable across generations and cultures. Harry Potter has become more than a story; it’s a shared cultural experience. However, with such influence comes controversy. Some critics argue that the franchise’s commercialization diluted its original message, while others challenge Rowling’s personal views and their impact on the fandom. Yet, the community’s resilience — seen in fan art, fanfiction, and activism — shows how readers have made the world their own. The Harry Potter phenomenon is proof that storytelling has the power to unite people, to inspire movements, and to build lasting cultural legacies. Whether you read it as a child or discovered it later in life, the series holds a special kind of magic that transcends pages and screens.\",\n",
        "    \"While Harry Potter is celebrated worldwide, it’s not immune to critical examination. From a literary standpoint, Rowling’s prose is often straightforward, prioritizing accessibility over stylistic complexity. Some argue that this simplicity makes the books less sophisticated compared to other fantasy epics like The Lord of the Rings or His Dark Materials. Moreover, critics point to certain limitations in world-building — particularly the underdeveloped treatment of non-European cultures and magical systems outside Britain. The series’ moral framework is also sometimes questioned. The dichotomy between “good” and “evil” can feel overly simplistic, with Slytherin House frequently vilified despite its potential for nuanced moral exploration. Additionally, Rowling’s representation of diversity has been criticized. The lack of significant non-white or LGBTQ+ characters has prompted important discussions about inclusivity in modern fantasy. Still, these criticisms do not erase the series’ achievements. Rowling succeeded in creating an emotionally compelling narrative that inspired millions to read. Her depiction of love, loss, and resilience resonates deeply with audiences. Perhaps Harry Potter’s imperfections are part of its legacy — they invite debate, reinterpretation, and reinvention by newer generations. In that sense, the series is both a triumph and a challenge, encouraging readers to imagine not only magical worlds but also more inclusive and complex ones.\",\n",
        "    \"The Harry Potter film adaptations stand as one of the most successful cinematic projects in history. Spanning a decade and eight movies, they managed to capture the essence of Rowling’s world while offering their own artistic interpretations. The casting was near-perfect — Daniel Radcliffe, Emma Watson, and Rupert Grint embodied their roles so naturally that they became inseparable from their characters. The production design of Hogwarts, Diagon Alley, and the Ministry of Magic remains visually iconic. Yet, adapting seven dense novels into eight films was no small feat. Some fans lament missing details and subplots, like the full backstory of the Marauders or the deeper moral struggles in The Order of the Phoenix. However, the films compensated with emotional weight and cinematic beauty. The direction evolved with the story’s tone: from the whimsical innocence of The Philosopher’s Stone under Chris Columbus to the haunting realism of The Deathly Hallows directed by David Yates. The musical score by John Williams added another layer of magic, immortalizing the franchise through its unforgettable motifs. The movies not only expanded the series’ reach but also created a visual language that continues to influence fantasy filmmaking. Despite inevitable compromises, the Harry Potter films transformed literature into an enduring cinematic legend.\",\n",
        "    \"Beyond wands and wizardry, Harry Potter is a profound meditation on morality. The series asks timeless ethical questions: What defines good and evil? Can love triumph over hate? How does power corrupt? Rowling’s narrative emphasizes that choices, not abilities, reveal a person’s true character — a philosophy echoed in Dumbledore’s wisdom. Through figures like Snape and Draco, the books explore moral ambiguity, showing that redemption and forgiveness are possible even for the deeply flawed. The theme of prejudice, especially through the treatment of “Muggle-borns” and “house-elves,” mirrors real-world discrimination. Rowling uses fantasy as a lens to discuss empathy and justice, encouraging readers to challenge bias in their own lives. Even Voldemort’s story, though steeped in evil, serves as a cautionary tale about the emptiness of power without love. The final message — that love is the most powerful magic — resonates universally. For many readers, Harry Potter functions almost like modern mythology, using the supernatural to explore what makes us human. Its moral lessons are not presented as lectures but as lived experiences, making them all the more impactful. Long after the final page, readers carry these values forward, proving that the truest magic lies not in spells, but in compassion and integrity.\",\n",
        "    \"For millions, Harry Potter represents more than just books — it’s a cherished part of childhood. The anticipation of each new release, the smell of freshly printed pages, and the long nights reading under blankets with a flashlight are memories that shaped an entire generation. The story became a shared experience — kids and adults alike waiting at midnight for the next chapter in Harry’s life. The sense of belonging was powerful: for those who felt out of place in the real world, Hogwarts became a second home. Growing up alongside Harry, Hermione, and Ron was a journey through both fiction and adolescence. When the series ended, many readers felt they were saying goodbye to friends. Revisiting the books now evokes deep nostalgia — a reminder of simpler times when magic felt real. Even as adults, readers still find comfort in Rowling’s universe, discovering new meaning in familiar passages. The series bridges generations; parents who once read it as children now share it with their own kids. That cyclical connection makes Harry Potter timeless. More than anything, the series proves that stories can become part of who we are — shaping our imagination, our empathy, and our sense of wonder long after we leave Hogwarts behind.\",\n",
        "    \"While Harry Potter brought joy to millions, its author’s fame has also sparked controversy. In recent years, public debate around J.K. Rowling’s personal statements has created division within the fandom. Some longtime fans feel conflicted — torn between love for the books and disappointment with their creator. This controversy raises complex questions about art and artist: can we separate the two? For many, the answer lies in the community itself. Fans have reclaimed the story, emphasizing the inclusive and accepting values they found within the pages, even when the author’s views seem to contradict them. The tension also highlights how deeply personal Harry Potter has become; it’s not just entertainment but part of people’s identities. The situation invites broader reflection on authorship and interpretation — once a story is released, does it still belong to its writer, or to the readers who give it life? Despite these challenges, the fandom remains resilient, using creativity and dialogue to sustain its magic. It’s a testament to the power of collective imagination: even when controversy clouds the legacy, the story’s message of love, courage, and unity continues to shine.\",\n",
        "    \"Few literary fandoms rival the passion of Harry Potter fans. From early internet forums to massive conventions, the community has become a cultural force of its own. Fans don’t just consume the story — they expand it. Through fanfiction, art, podcasts, and activism, they’ve kept Hogwarts alive long after the final book. Websites like MuggleNet and The Leaky Cauldron fostered discussions, while fan-made works like A Very Potter Musical and The Wizarding World theme parks demonstrate the creativity born from this shared love. The fandom also became a space for social activism. Organizations like the Harry Potter Alliance use the story’s themes to promote equality and education, proving that fiction can inspire real-world change. This participatory culture gives Harry Potter a life independent of its author. It belongs to the readers who found empowerment and belonging within its pages. The community’s inclusivity and innovation are reminders that stories thrive when shared. The Harry Potter fandom isn’t just a byproduct of success — it’s a living example of how narrative worlds can evolve through collaboration and imagination, bridging the gap between fiction and reality.\",\n",
        "    \"More than two decades since its debut, Harry Potter continues to enchant new generations. Its legacy extends far beyond bookshelves — influencing literature, cinema, and even education. The series taught readers to value empathy, knowledge, and courage. It reminded them that family isn’t always defined by blood and that standing up for what’s right matters, even when it’s difficult. Teachers use the books to spark discussions about ethics, prejudice, and identity. Psychologists cite them as examples of literature that nurtures emotional intelligence. Beyond academia, Harry Potter’s impact is emotional and universal. It provided solace to those who felt invisible and hope to those facing adversity. Despite controversies and criticisms, its central message remains untarnished: love conquers fear. As readers revisit the series, they discover that the true magic lies not in spells, but in the human heart. The story endures because it evolves — each generation finds new meaning in its words. Ultimately, Harry Potter is more than a cultural phenomenon; it’s a global symbol of imagination, resilience, and the timeless belief that even the smallest person can change the world.\"\n",
        "    #\"Text 10 – replace me with your own text.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fxlqsSg6mrY"
      },
      "source": [
        "## 3 – Load the SentenceTransformer model\n",
        "\n",
        "**Tasks:**\n",
        "- Load the `all-MiniLM-L6-v2` using `SentenceTransformer()` and apply it to a sentence of your choice to show the embeddings.\n",
        "- Explain what the embeddings are on a short sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-116cy86drF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mps\n",
            "/Volumes/hack/projects/data-mining-htw/.pixi/envs/default/lib/python3.13/site-packages/certifi/cacert.pem\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "    Load a lightweight embedding model from Huggingface\n",
        "'''\n",
        "# Use gpu to speed-up the proccess if available, otherwise use cpu(20 min already).\n",
        "device = torch.device(\"mps\" if torch.mps.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "import certifi\n",
        "print(certifi.where())\n",
        "\n",
        "# The SentenceTransformer(a.k.a SBERT) is a python module that is trained on state-of-the-art embeddings models.\n",
        "\n",
        "#model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=device,token=False )\n",
        "model = SentenceTransformer(model_name_or_path=\"../model\", device=device)\n",
        "\n",
        "#Compute the embbedings by using the previous model\n",
        "embeddings = model.encode(texts, show_progress_bar=True)\n",
        "print(embeddings.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emBFhElX6uVl"
      },
      "source": [
        "**Explanation:** ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Fidel's answer:** <br>\n",
        "Embeddings are numerical column vector representation of words, sentences, paragraphs, etc. In order to achieve vector representation of the words, sentences, or paragraphs; these have to be split into **tokens** and each token is converted to a numerical value and these numeric values are grouped togheter on the size of the **context window**; the context window is choosen based on many approaches(similarity, context, word reelevance, etc.). Ultimately, these numbers are put in a single column vector which is the vector that embeds a representation of the word, sentences, or paragraphs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlW2XevJ68mv"
      },
      "source": [
        "## 4 – Create and fill an in-memory SQLite database\n",
        "\n",
        "- Create an in-memory database with SQLite\n",
        "- Create a table with the fields\n",
        "  - id,\n",
        "  - title,\n",
        "  - text,\n",
        "  - embedding,\n",
        "  - import_time\n",
        "- Metadata: Just add the time you loaded the data into the database\n",
        "- Load the data into the database: `INSERT INTO documents (title, text, embedding, import_time) VALUES (?, ?, ?, ?)`\n",
        "- Use pandas to run a SQL-request against the table to show that everything works fine\n",
        "\n",
        "**Task:** Add the necessary SQL query. All other parts are already there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8t4IuIdO6tfA"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(texts):\n\u001b[32m     20\u001b[39m     title = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDoc_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     emb = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m     22\u001b[39m     emb_str = \u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, emb))   \u001b[38;5;66;03m# convert vector to comma-separated string\u001b[39;00m\n\u001b[32m     23\u001b[39m     cursor.execute(\n\u001b[32m     24\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mINSERT INTO documents (title, text, embedding, import_time) VALUES (?, ?, ?, ?)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     25\u001b[39m         (title, t, emb_str, \u001b[38;5;28mstr\u001b[39m(datetime.datetime.now()))\n\u001b[32m     26\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/hack/projects/data-mining-htw/.pixi/envs/default/lib/python3.13/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/hack/projects/data-mining-htw/.pixi/envs/default/lib/python3.13/site-packages/sentence_transformers/SentenceTransformer.py:1060\u001b[39m, in \u001b[36mSentenceTransformer.encode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[39m\n\u001b[32m   1057\u001b[39m length_sorted_idx = np.argsort([-\u001b[38;5;28mself\u001b[39m._text_length(sen) \u001b[38;5;28;01mfor\u001b[39;00m sen \u001b[38;5;129;01min\u001b[39;00m sentences])\n\u001b[32m   1058\u001b[39m sentences_sorted = [sentences[\u001b[38;5;28mint\u001b[39m(idx)] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m length_sorted_idx]\n\u001b[32m-> \u001b[39m\u001b[32m1060\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m start_index \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrange\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mBatches\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1061\u001b[39m     sentences_batch = sentences_sorted[start_index : start_index + batch_size]\n\u001b[32m   1062\u001b[39m     features = \u001b[38;5;28mself\u001b[39m.tokenize(sentences_batch, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/hack/projects/data-mining-htw/.pixi/envs/default/lib/python3.13/site-packages/tqdm/notebook.py:312\u001b[39m, in \u001b[36mtnrange\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtnrange\u001b[39m(*args, **kwargs):\n\u001b[32m    311\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Shortcut for `tqdm.notebook.tqdm(range(*args), **kwargs)`.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtqdm_notebook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/hack/projects/data-mining-htw/.pixi/envs/default/lib/python3.13/site-packages/tqdm/std.py:665\u001b[39m, in \u001b[36mtqdm.__new__\u001b[39m\u001b[34m(cls, *_, **__)\u001b[39m\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, *_, **__):\n\u001b[32m    664\u001b[39m     instance = \u001b[38;5;28mobject\u001b[39m.\u001b[34m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m665\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:  \u001b[38;5;66;03m# also constructs lock if non-existent\u001b[39;00m\n\u001b[32m    666\u001b[39m         \u001b[38;5;28mcls\u001b[39m._instances.add(instance)\n\u001b[32m    667\u001b[39m         \u001b[38;5;66;03m# create monitoring thread\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/hack/projects/data-mining-htw/.pixi/envs/default/lib/python3.13/site-packages/tqdm/std.py:764\u001b[39m, in \u001b[36mtqdm.get_lock\u001b[39m\u001b[34m(cls)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Get the global lock. Construct it if it does not exist.\"\"\"\u001b[39;00m\n\u001b[32m    763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m_lock\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     \u001b[38;5;28mcls\u001b[39m._lock = \u001b[43mTqdmDefaultWriteLock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    765\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._lock\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/hack/projects/data-mining-htw/.pixi/envs/default/lib/python3.13/site-packages/tqdm/std.py:96\u001b[39m, in \u001b[36mTqdmDefaultWriteLock.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     94\u001b[39m root_lock = \u001b[38;5;28mcls\u001b[39m.th_lock\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m root_lock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     \u001b[43mroot_lock\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28mcls\u001b[39m.create_mp_lock()\n\u001b[32m     98\u001b[39m \u001b[38;5;28mself\u001b[39m.locks = [lk \u001b[38;5;28;01mfor\u001b[39;00m lk \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mcls\u001b[39m.mp_lock, \u001b[38;5;28mcls\u001b[39m.th_lock] \u001b[38;5;28;01mif\u001b[39;00m lk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Create an in-memory database\n",
        "conn = sqlite3.connect(\":memory:\")\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Create a simple table (embedding stored as TEXT)\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS documents (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    title TEXT NOT NULL,\n",
        "    text TEXT NOT NULL,\n",
        "    embedding BLOB,\n",
        "    import_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        ")\n",
        "\"\"\")\n",
        "\n",
        "# Insert documents with metadata\n",
        "import datetime\n",
        "#model2 = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\", device=device)\n",
        "for i, t in enumerate(texts):\n",
        "    title = f\"Doc_{i+1}\"\n",
        "    emb = model.encode([t])[0]\n",
        "    emb_str = \",\".join(map(str, emb))   # convert vector to comma-separated string\n",
        "    cursor.execute(\n",
        "        \"INSERT INTO documents (title, text, embedding, import_time) VALUES (?, ?, ?, ?)\",\n",
        "        (title, t, emb_str, str(datetime.datetime.now()))\n",
        "    )\n",
        "\n",
        "conn.commit()\n",
        "\n",
        "# Test query using pandas\n",
        "pd.read_sql(\"SELECT id, title, import_time FROM documents\", conn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miWwnRsy8SPA"
      },
      "source": [
        "## 5 – Define and test three similarity metrics\n",
        "\n",
        "- **Task:** Please build to more functions. The functions should return a similarity score between two vectors.\n",
        "- Will be used later to compare which metric retrieves the most relevant texts.\n",
        "\n",
        "Here is one function:\n",
        "\n",
        "```\n",
        "# Metric 1: cosine similarity (from scikit-learn)\n",
        "def cosine_sim(a, b):\n",
        "    return cosine_similarity(a.reshape(1, -1), b.reshape(1, -1))[0][0]\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tt7hW0WS7r2U"
      },
      "outputs": [],
      "source": [
        "# Metric 1: cosine similarity (from scikit-learn)\n",
        "def cosine_sim(a, b):\n",
        "    return cosine_similarity(a.reshape(1, -1), b.reshape(1, -1))[0][0]\n",
        "\n",
        "# Metric 2:\n",
        "def\n",
        "\n",
        "\n",
        "# Metric 3:\n",
        "def\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpE3vv-j8Xke"
      },
      "source": [
        "## 6 – Build a simple Retriever\n",
        "\n",
        "A function that encodes a query, computes the similarity between the query and each document embedding, and returns the top 3 most similar texts by default.  \n",
        "  \n",
        "**Task: Code is complete, please explain what happens here**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UD_FaJJh8q91"
      },
      "outputs": [],
      "source": [
        "def retrieve(query, metric_function, top_k=3):\n",
        "    # Encode the query\n",
        "    q_vec = model.encode([query])[0]\n",
        "\n",
        "    # Load all document embeddings\n",
        "    cursor.execute(\"SELECT id, title, text, embedding FROM documents\")\n",
        "    docs = cursor.fetchall()\n",
        "\n",
        "    results = []\n",
        "    for doc_id, title, text, emb_str in docs:\n",
        "        emb = np.fromstring(emb_str, sep=\",\")     # convert text back to numeric vector\n",
        "        score = metric_function(q_vec, emb)\n",
        "        results.append((title, text, score))\n",
        "\n",
        "    # Sort by similarity and return top_k results\n",
        "    results = sorted(results, key=lambda x: x[2], reverse=True)[:top_k]\n",
        "    return pd.DataFrame(results, columns=[\"Title\", \"Text\", \"Score\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNSJvgfcQsA-"
      },
      "source": [
        "**Explanation**\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsWTRw0Z_BB0"
      },
      "source": [
        "## 7 – Run a query and inspect the results\n",
        "\n",
        "- Run the retriever with one of the metrics (cosine_sim, dot_product_sim, or inv_euclidean_sim).\n",
        "- Check how the ranking of results changes across metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqrWCS8m8slI"
      },
      "outputs": [],
      "source": [
        "query = \"Enter your own test question here\"\n",
        "retrieve(query, cosine_sim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCZeANDC_H5X"
      },
      "source": [
        "# Fine-Tuning Phase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwDVaUje_LDt"
      },
      "source": [
        "## 8 – Reload database with different chunk sizes and overlaps\n",
        "\n",
        "- Reload your in-memory database with various chunk_size and overlap settings (e.g. 30/10, 60/20).\n",
        "- For each configuration, insert each chunk as a new row in the documents table and repeat the insertion logic from Section 4 (using comma-separated embeddings).\n",
        "\n",
        "**Task:** Explain what happens here and test the functions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7sLualE_JW2"
      },
      "outputs": [],
      "source": [
        "def chunk_text(text, chunk_size=50, overlap=10):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    for i in range(0, len(words), chunk_size - overlap):\n",
        "        chunk = \" \".join(words[i:i+chunk_size])\n",
        "        if chunk.strip():\n",
        "            chunks.append(chunk)\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlPMlFjdQ9Fp"
      },
      "source": [
        "**Explanations:** ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFHMT4pUQ-7_"
      },
      "outputs": [],
      "source": [
        "# Test the function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZT7Rhcj_StG"
      },
      "source": [
        "## 9 – Query the new database with different similarity metrics\n",
        "\n",
        "Compare retrieval quality under the different metrics developed above. A record which combination of metric, chunk size, and overlap yields the most meaningful matches will be printed out.\n",
        "\n",
        "**Task:** Replace the similarity-functions here with the functions you developed above:\n",
        "\n",
        "```\n",
        "for metric in [cosine_sim, <your sim function>, <your sim function>]:\n",
        "    print(f\"Results using {metric.__name__}:\")\n",
        "    display(retrieve(query, metric))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WputV4ZL_Mpl"
      },
      "outputs": [],
      "source": [
        "for metric in [cosine_sim, dot_product_sim, inv_euclidean_sim]:\n",
        "    print(f\"Results using {metric.__name__}:\")\n",
        "    display(retrieve(query, metric))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3onl0c-n_Zbq"
      },
      "source": [
        "## 10 – Use the systematic evaluation module\n",
        "\n",
        "- This module systematically tests different configurations (chunk size, overlap, metric) and records which text was ranked highest.\n",
        "- Visualize or summarize the outcomes to decide which configuration works best.\n",
        "\n",
        "**Task:** Explain what happens here and run the experiment with different settings for\n",
        "- chunksize\n",
        "- overlap\n",
        "- similarity functions\n",
        "\n",
        "(Modify the experiment if you want, but not necessary or required).\n",
        "\n",
        "*Please note: Replace the similarity functions with your similarity functions, otherwise it will throw an error.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1a2X8kA_UZa"
      },
      "outputs": [],
      "source": [
        "def evaluate_configs(query, chunk_sizes, overlaps, metrics):\n",
        "    results = []\n",
        "\n",
        "    for cs in chunk_sizes:\n",
        "        for ov in overlaps:\n",
        "            # Rebuild an in-memory DB for each configuration\n",
        "            conn = sqlite3.connect(\":memory:\")\n",
        "            cursor = conn.cursor()\n",
        "            cursor.execute(\"CREATE TABLE docs (id INTEGER PRIMARY KEY, text TEXT, embedding TEXT)\")\n",
        "\n",
        "            # Insert chunks with textual embeddings\n",
        "            for t in texts:\n",
        "                for ch in chunk_text(t, cs, ov):\n",
        "                    emb = model.encode([ch])[0]\n",
        "                    emb_str = \",\".join(map(str, emb))\n",
        "                    cursor.execute(\"INSERT INTO docs (text, embedding) VALUES (?, ?)\", (ch, emb_str))\n",
        "            conn.commit()\n",
        "\n",
        "            # Encode the query once\n",
        "            q_vec = model.encode([query])[0]\n",
        "\n",
        "            # Evaluate all metrics\n",
        "            for metric in metrics:\n",
        "                cursor.execute(\"SELECT id, text, embedding FROM docs\")\n",
        "                docs = cursor.fetchall()\n",
        "                scores = []\n",
        "\n",
        "                for _, text, emb_str in docs:\n",
        "                    emb = np.fromstring(emb_str, sep=\",\")\n",
        "                    score = metric(q_vec, emb)\n",
        "                    scores.append((text, score))\n",
        "\n",
        "                # Sort by similarity and take the best one\n",
        "                top_text, top_score = sorted(scores, key=lambda x: x[1], reverse=True)[0]\n",
        "\n",
        "                results.append((cs, ov, metric.__name__, top_text, top_score))\n",
        "\n",
        "    # Return results as DataFrame\n",
        "    return pd.DataFrame(results, columns=[\"ChunkSize\", \"Overlap\", \"Metric\", \"TopResult\", \"SimilarityScore\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06SmnkMNRiyY"
      },
      "source": [
        "**Explanations:** ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnA-aMAh_rL4"
      },
      "source": [
        "**Example usage**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcBkU-Oq_qfp"
      },
      "outputs": [],
      "source": [
        "# Define your test query\n",
        "query = \"Summarize the main idea of my texts\"\n",
        "\n",
        "# Define parameter grid\n",
        "chunk_sizes = [30, 50, 70]\n",
        "overlaps = [5, 10, 15]\n",
        "metrics = [cosine_sim, dot_product_sim, inv_euclidean_sim]\n",
        "\n",
        "# Run evaluation\n",
        "results_df = evaluate_configs(query, chunk_sizes, overlaps, metrics)\n",
        "\n",
        "# Display full table\n",
        "display(results_df)\n",
        "\n",
        "# Optional: Find the highest similarity overall\n",
        "best_config = results_df.sort_values(\"SimilarityScore\", ascending=False).head(1)\n",
        "display(best_config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkvMzJjQR5-s"
      },
      "source": [
        "**Interpretation of Results** ..."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "default",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
